{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d044f1-b0f7-424c-85bd-bc38464baf7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -q google-cloud-aiplatform==1.36.0 langchain==0.0.327 unstructured chromadb==0.4.15 --upgrade --user \"unstructured[pdf]\" pydantic gradio pdf2image google-cloud-vision google-cloud-storage pymupdf easyocr numpy python-docx python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5577e564-bc09-4a46-bcaa-00337e3e19f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -q langchain==0.0.327 chromadb==0.4.15 gradio google-cloud-storage pymupdf easyocr numpy python-docx python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bff5fe0c-acb1-40b4-bf0e-9e6e6fcfaedd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "import time\n",
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da524b-3ebd-4514-b650-a774405f37f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84bf92b-59a4-4b3e-a05f-733bd6eeb2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 19:24:08.226157: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 19:24:09.853942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-09-25 19:24:09.854183: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-09-25 19:24:09.854197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "import vertexai\n",
    "from google.cloud import storage\n",
    "import fitz  # PyMuPDF\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import docx\n",
    "import pptx\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import gradio as gr\n",
    "import datetime  \n",
    "import os\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b44175-efcd-4a2c-8535-34db633458ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize GCP Storage client\n",
    "def initialize_gcp():\n",
    "    # Initialize Vertex AI SDK\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "    # Initialize Google Cloud Storage client\n",
    "    storage_client = storage.Client()\n",
    "    return storage_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37ffd8-55f5-46b4-9d2d-a2a8708a2614",
   "metadata": {},
   "source": [
    "# Global vars & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c9b246-949b-4b1f-80ef-da91319436ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"genai-vertex-poc\"\n",
    "LOCATION = \"us-central1\" \n",
    "BUCKET_NAME = \"data88\"\n",
    "GCP_STORAGE_CLIENT = initialize_gcp()\n",
    "TEMP_FOLDER = \"_temp/\"\n",
    "\n",
    "DB_PATH = \"chroma_db5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d1bf08-481d-4043-b8db-3a58d183344f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Text Embeddings model\n",
    "# embedding = VertexAIEmbeddings(model_name='text-embedding-004')\n",
    "embedding = VertexAIEmbeddings()\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison-32k\",\n",
    "    max_output_tokens=256,\n",
    "    temperature=0.1,\n",
    "    top_p=0.6,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e30e46-15df-4d77-b5de-08cd67a5d0e5",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebfa44d-5313-45b6-84f4-87a8facbec12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to add text to dictionary key\n",
    "def add_text_to_key(my_dict, key, text):\n",
    "    my_dict.setdefault(key, '')  # Initialize key with empty string if not present\n",
    "    my_dict[key] += text\n",
    "    \n",
    "def download_from_gcs(bucket_name, blob_name, destination_file_name):    \n",
    "    bucket = GCP_STORAGE_CLIENT.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "def get_or_create_bucket(bucket_name):\n",
    "    try:\n",
    "        # Get the bucket\n",
    "        bucket = GCP_STORAGE_CLIENT.bucket(bucket_name)\n",
    "    except:\n",
    "        # Create the bucket if it doesn't exist\n",
    "        bucket = GCP_STORAGE_CLIENT.create_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name[:-6]} created.\")\n",
    "\n",
    "    return bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdffa1f-645e-47e2-a825-5aa0375f6484",
   "metadata": {},
   "source": [
    "# Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc1973d-9fe4-47bb-b95b-ce343f83aef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_images_from_file(file_path):\n",
    "    images = []\n",
    "\n",
    "    if file_path.endswith('.pdf'):\n",
    "        doc = fitz.open(file_path)\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            pix = page.get_pixmap()\n",
    "            img_bytes = pix.tobytes()\n",
    "            img = Image.open(io.BytesIO(img_bytes))\n",
    "            images.append(np.array(img))  # Convert PIL.Image to numpy array\n",
    "        doc.close()\n",
    "\n",
    "    elif file_path.endswith('.docx'):\n",
    "        doc = docx.Document(file_path)\n",
    "        for rel in doc.part.rels.values():\n",
    "            if \"image\" in rel.target_ref:\n",
    "                img_bytes = rel.target_part.blob\n",
    "                img = Image.open(io.BytesIO(img_bytes))\n",
    "                images.append(np.array(img))  # Convert PIL.Image to numpy array\n",
    "\n",
    "    elif file_path.endswith('.pptx'):\n",
    "        ppt = pptx.Presentation(file_path)\n",
    "        for slide in ppt.slides:\n",
    "            for shape in slide.shapes:\n",
    "                if shape.shape_type == 13:  # 13 is the type for Picture\n",
    "                    image = shape.image\n",
    "                    img_bytes = image.blob\n",
    "                    img = Image.open(io.BytesIO(img_bytes))\n",
    "                    images.append(np.array(img))  # Convert PIL.Image to numpy array\n",
    "    else:\n",
    "        print('Unsupported file format')\n",
    "        return None\n",
    "    # print('extract_images_from_file executed')\n",
    "    return images\n",
    "\n",
    "# Function to perform OCR using EasyOCR\n",
    "def perform_ocr(image):\n",
    "    reader = easyocr.Reader(['en'])  # Replace with desired language(s)\n",
    "    result = reader.readtext(image)\n",
    "    text = '\\n'.join([bbox[1] for bbox in result])\n",
    "    # print('perform_ocr executed')\n",
    "    return text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    combined_text = ''\n",
    "    dict_pagenumber_text = {}\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        combined_text += page_text\n",
    "        dict_pagenumber_text[page_num + 1] = page_text # Page numbers start from 1\n",
    "    doc.close()\n",
    "    # print('extract_text_from_pdf executed')\n",
    "    return combined_text, dict_pagenumber_text\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    print(\"file_path\", file_path)\n",
    "    document = docx.Document(file_path)\n",
    "    dict_pagenumber_text = {}\n",
    "    current_page = 0\n",
    "    page_content = []\n",
    "    combined_text = []\n",
    "\n",
    "    for paragraph in document.paragraphs:\n",
    "        for run in paragraph.runs:\n",
    "            # Check for page break in the run\n",
    "            if 'lastRenderedPageBreak' in run._element.xml:\n",
    "                page_content.append(run.text)\n",
    "                combined_text.append(run.text)\n",
    "                dict_pagenumber_text[current_page] = ' '.join(page_content).strip()\n",
    "                current_page += 1\n",
    "                page_content = []\n",
    "            else:\n",
    "                page_content.append(run.text)\n",
    "                combined_text.append(run.text)\n",
    "        page_content.append('\\n')  # Add a newline to separate paragraphs\n",
    "        combined_text.append('\\n')\n",
    "\n",
    "    # Add the last page\n",
    "    if page_content:\n",
    "        dict_pagenumber_text[current_page] = ' '.join(page_content).strip()\n",
    "\n",
    "    combined_text = ''.join(combined_text).strip()\n",
    "    return combined_text, dict_pagenumber_text\n",
    "\n",
    "\n",
    "def extract_text_from_pptx(pptx_path):\n",
    "    ppt = pptx.Presentation(pptx_path)\n",
    "    combined_text = ''\n",
    "    dict_pagenumber_text = {}\n",
    "    for slide_num, slide in enumerate(ppt.slides):\n",
    "        slide_text = ''\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                slide_text += shape.text_frame.text\n",
    "        combined_text += slide_text\n",
    "        dict_pagenumber_text[slide_num + 1] = slide_text # Slide numbers start from 1\n",
    "    # print('extract_text_from_pptx executed')\n",
    "    return combined_text, dict_pagenumber_text\n",
    "\n",
    "\n",
    "def extract_text(bucket_name, blob_name):\n",
    "    # Create the \"_temp\" folder if it doesn't exist\n",
    "    os.makedirs(TEMP_FOLDER, exist_ok=True)\n",
    "    destination_file_name = os.path.join(TEMP_FOLDER, f'downloaded_{blob_name}')\n",
    "    download_from_gcs(bucket_name, blob_name, destination_file_name)\n",
    "\n",
    "    combined_text = \"\"\n",
    "    dict_pagenumber_text = {}\n",
    "    metadata = {\n",
    "        \"file_name\": blob_name,\n",
    "        \"file_type\": os.path.splitext(blob_name)[1],\n",
    "        \"upload_date_time\": str(datetime.datetime.now())\n",
    "    }\n",
    "\n",
    "    if destination_file_name.endswith('.pdf'):\n",
    "        combined_text, dict_pagenumber_text = extract_text_from_pdf(destination_file_name)\n",
    "    elif destination_file_name.endswith('.docx'):\n",
    "        combined_text, dict_pagenumber_text = extract_text_from_docx(destination_file_name)\n",
    "    elif destination_file_name.endswith('.pptx'):\n",
    "        combined_text, dict_pagenumber_text = extract_text_from_pptx(destination_file_name)\n",
    "    elif destination_file_name.endswith('.txt'):\n",
    "        with open(destination_file_name) as fp:\n",
    "            combined_text = fp.read()\n",
    "            dict_pagenumber_text = {1: combined_text}\n",
    "    else:\n",
    "        print('Unsupported file format')\n",
    "        #metadata[\"processing_status\"] = \"Failed: Unsupported file format\"\n",
    "        return \"\", {}, {}\n",
    "\n",
    "    images = extract_images_from_file(destination_file_name)\n",
    "    for i, image in enumerate(images):\n",
    "        ocr_text = perform_ocr(image)\n",
    "        combined_text += \"\\n\" + ocr_text\n",
    "        add_text_to_key(dict_pagenumber_text, i, ocr_text)\n",
    "\n",
    "    os.remove(destination_file_name)\n",
    "    # print('process_file executed and metadata is: ', metadata)\n",
    "    return combined_text, metadata, dict_pagenumber_text\n",
    "\n",
    "\n",
    "def process_blobs_concurrently(bucket_name, blobs, max_workers=4):    \n",
    "    # blobs = list(GCP_STORAGE_CLIENT.list_blobs(bucket_name))\n",
    "    combined_text_all_files = \"\"\n",
    "    # {filename: dict_metadata}\n",
    "    metadata_all_files = {}\n",
    "    # {filename: dict_pagenumber_text}\n",
    "    dict_pagenumber_text_all_files = {}\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_blob = {executor.submit(extract_text, bucket_name, blob.name): blob for blob in blobs}\n",
    "        for future in concurrent.futures.as_completed(future_to_blob):\n",
    "            blob = future_to_blob[future]\n",
    "            print(\"Processing :\", blob)\n",
    "            try:\n",
    "                combined_text, metadata, dict_pagenumber_text = future.result()\n",
    "                if combined_text:\n",
    "                    combined_text_all_files += combined_text\n",
    "                    metadata_all_files[blob.name] = metadata\n",
    "                    dict_pagenumber_text_all_files[blob.name] = dict_pagenumber_text\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {blob.name}: {e}\")\n",
    "    return combined_text_all_files, metadata_all_files, dict_pagenumber_text_all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f5762c-94ca-4b2b-b1db-fd73e7e484c1",
   "metadata": {},
   "source": [
    "# Vector DB Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8eaa5ca-8ee6-4b7f-a18d-6521617545aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHROMA_DB_CLIENT = chromadb.PersistentClient(path = DB_PATH)\n",
    "\n",
    "def del_collection(collection_name):\n",
    "    CHROMA_DB_CLIENT.delete_collection(collection_name)\n",
    "    return f\"Collection {collection_name} deleted Successfully!\"\n",
    "\n",
    "def get_all_collections():\n",
    "    # Function to get the list of all collections\n",
    "    collections = CHROMA_DB_CLIENT.list_collections()\n",
    "    collection_names = [col.name for col in collections]\n",
    "    return collection_names\n",
    "\n",
    "def get_files_in_collection(collection_name):\n",
    "    # Function to get the list of files in a given collection\n",
    "    try:\n",
    "        collection = CHROMA_DB_CLIENT.get_collection(collection_name)\n",
    "        documents = collection.get()\n",
    "        \n",
    "        # Prepare a list to store file details\n",
    "        file_details = {}\n",
    "        \n",
    "        for i in range(len(documents['ids'])):\n",
    "            file_details[documents['metadatas'][i]['file_name']] = {'Upload Date Time': documents['metadatas'][i]['upload_date_time']}\n",
    "        \n",
    "        return file_details\n",
    "    \n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751e49d-1827-4023-b9fe-2489e193fb76",
   "metadata": {},
   "source": [
    "# split_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adaa43d0-aba7-4f87-af91-48ce9aa81974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, page_content, metadata={}):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "\n",
    "def split_documents(metadata_all_files, dict_pagenumber_text_all_files):\n",
    "    documents = []\n",
    "    for filename, dict_pagenumber_text in dict_pagenumber_text_all_files.items():\n",
    "        for page_num, page_content in dict_pagenumber_text.items():\n",
    "            doc = Document(page_content=page_content, metadata= metadata_all_files[filename]|{\"page_number\": page_num})\n",
    "            documents.append(doc)\n",
    "    #print('documents: ',documents)    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    #print('split_docs: ',split_docs)\n",
    "    print(f\"# of documents = {len(split_docs)}\")\n",
    "    # print('split_documents executed')\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9082c2a-ecba-4465-be60-d1b33be54186",
   "metadata": {},
   "source": [
    "# Process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69da79b6-5d01-4ad7-9e3b-29382b168942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_documents(bucket_name, collection_name, blobs):\n",
    "    combined_text_all_files, metadata_all_files, dict_pagenumber_text_all_files = process_blobs_concurrently(bucket_name, blobs, 2)\n",
    "    docs = split_documents(metadata_all_files, dict_pagenumber_text_all_files)\n",
    "    # save documents' embeddings in Chroma\n",
    "    db = Chroma.from_documents(docs, embedding, collection_name= collection_name, persist_directory=DB_PATH)\n",
    "    return db\n",
    "\n",
    "# Function to validate collection name\n",
    "def is_valid_collection_name(name):\n",
    "    # Check if the name is at least 3 characters long\n",
    "    if len(name) < 3:\n",
    "        return False\n",
    "    # Check if the name contains only alphanumeric characters, underscores, and hyphens\n",
    "    if not re.match(r'^[a-zA-Z0-9_-]+$', name):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Upload files to GCP\n",
    "def upload_and_process_documents(files, collection_name):\n",
    "    if not is_valid_collection_name(collection_name):\n",
    "        return '''Invalid collection name. Please follow the naming guidelines.\\nNaming Guidelines: \n",
    "    minimum length of 3 characters, and allowing only alphanumeric characters, underscores, and hyphens'''\n",
    "    bucket = get_or_create_bucket(BUCKET_NAME)\n",
    "\n",
    "    blobs = []\n",
    "    for file in files:\n",
    "        file_name = os.path.basename(file.name)\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(file.name)\n",
    "        blobs.append(blob)\n",
    "\n",
    "    process_documents(BUCKET_NAME, collection_name, blobs)\n",
    "    return \"Uploaded files successfully in Collection: \" + collection_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80136ffe-09b9-489b-b24f-21e18b861503",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e24a0a-a00e-4964-a89c-3a16a2b10ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://afcb9d04f065885807.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://afcb9d04f065885807.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : <Blob: data88, Format_MResult Resume.pptx, 1727292332184099>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : <Blob: data88, OCR__RAG_based_chatbot.pdf, 1727292331901251>\n",
      "# of documents = 18\n"
     ]
    }
   ],
   "source": [
    "# Define the Gradio app using Blocks\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# OCR_based_gpt\")\n",
    "    gr.Markdown(\"Upload and manage your documents here!\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Upload Files Section\n",
    "            gr.Markdown(\"## Upload & Process Files\")\n",
    "            file_upload = gr.File(label=\"Upload Files\", file_count=\"multiple\")\n",
    "            collection_name_input = gr.Textbox(label=\"Collection Name\", placeholder=\"Enter Collection Name\")\n",
    "            upload_button = gr.Button(\"Upload and Process\")\n",
    "            upload_output = gr.Textbox(label=\"Upload Response\")\n",
    "            \n",
    "            upload_button.click(\n",
    "                upload_and_process_documents,\n",
    "                inputs=[file_upload, collection_name_input],\n",
    "                outputs=upload_output\n",
    "            )\n",
    "            \n",
    "            # Delete Collection Section\n",
    "            gr.Markdown(\"## Delete Collection\")\n",
    "            collection_name_input = gr.Textbox(label=\"Collection Name\", placeholder=\"Enter Collection Name\")\n",
    "            delete_collection_btn = gr.Button(\"Delete Collection\")\n",
    "            delete_collection_output = gr.Textbox(label=\"Delete Response\")\n",
    "            \n",
    "            delete_collection_btn.click(\n",
    "                del_collection,\n",
    "                inputs=collection_name_input,\n",
    "                outputs=delete_collection_output\n",
    "            )\n",
    "\n",
    "        with gr.Column():\n",
    "            # List Collections Section\n",
    "            gr.Markdown(\"## Get All Collections\")\n",
    "            all_collections_output = gr.JSON(label=\"All Collections\")\n",
    "            list_collections_btn = gr.Button(\"List All Collections\")\n",
    "            \n",
    "            list_collections_btn.click(\n",
    "                get_all_collections,\n",
    "                inputs=[],\n",
    "                outputs=all_collections_output\n",
    "            )\n",
    "        \n",
    "            # List Files in Collection Section\n",
    "            gr.Markdown(\"## Get Files in Collection\")\n",
    "            collection_name_input_files = gr.Textbox(label=\"Collection Name\", placeholder=\"Enter Collection Name\")\n",
    "            files_output = gr.JSON(label=\"Files in Collection\")\n",
    "            list_files_btn = gr.Button(\"List Files in Collection\")\n",
    "            \n",
    "            list_files_btn.click(\n",
    "                get_files_in_collection,\n",
    "                inputs=collection_name_input_files,\n",
    "                outputs=files_output\n",
    "            )\n",
    "\n",
    "\n",
    "# Launch the Gradio app\n",
    "app.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bccb7b-1a54-496e-8b25-3a2309726316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0e110d5-45c3-4ee7-a89c-637ef1659403",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24267cff-bd90-404b-ba3f-09adf7785ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
